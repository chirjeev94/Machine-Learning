{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Pre-processing Data-----\n",
      "------Done Pre-processing Data -----\n",
      "Total time taken: 234.0340130329132\n",
      "0.354125\n",
      "0.564\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import time\n",
    "\n",
    "def build_step_for_feature(image_matrix):\n",
    "    move_step = []\n",
    "\n",
    "    for i in range(image_matrix.shape[1]):\n",
    "        #a = SortedSet(image_matrix[:,i].tolist())\n",
    "        move_step.append(a)\n",
    "    \n",
    "    return move_step\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,feature,threshold,left,right,label):\n",
    "        self.feature=feature\n",
    "        self.threshold=threshold\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.label=label\n",
    "\n",
    "def calculate_max_label_count(labels):\n",
    "    count_map={}\n",
    "    for i in range(len(labels)):\n",
    "        if not(labels[i] in count_map):\n",
    "            count_map[labels[i]]=1\n",
    "        else:\n",
    "            count_map[labels[i]]=count_map[labels[i]]+1\n",
    "            \n",
    "     ##check this       \n",
    "    return max(count_map.values())\n",
    "        \n",
    "def calculate_max_label(labels):\n",
    "    count_map={}\n",
    "    curr_max=0\n",
    "    max_label=0\n",
    "    for i in range(len(labels)):\n",
    "        if not(labels[i] in count_map):\n",
    "            count_map[labels[i]]=1\n",
    "        else:\n",
    "            count_map[labels[i]]=count_map[labels[i]]+1\n",
    "        if(count_map[labels[i]]>curr_max):\n",
    "            curr_max=count_map[labels[i]]\n",
    "            max_label=labels[i]\n",
    "     ##check this       \n",
    "    return max_label\n",
    "\n",
    "def entropy(labels):\n",
    "    if labels is None or len(labels)==0:\n",
    "        return 0;\n",
    "    return (len(labels)-calculate_max_label_count(labels))*1.0*(1.0/len(labels))\n",
    "    \n",
    "def shuffle_and_split(data,partition):\n",
    "    ran_order = np.arange(len(data['X']))\n",
    "    np.random.shuffle(ran_order)\n",
    "    ran_order_training = ran_order[:(int)(len(data['X'])*partition)] \n",
    "    ran_order_test = ran_order[(int)(len(data['X'])*partition):] \n",
    "    training_data = data['X'][ran_order_training]\n",
    "    training_label = data['Y'][ran_order_training]\n",
    "    test_data = data['X'][ran_order_test]\n",
    "    test_label = data['Y'][ran_order_test]\n",
    "    return [training_data,training_label,test_data,test_label]\n",
    "\n",
    "def calculate_optimal_feature_threshold(feature_space,labels):\n",
    "    opt_f=0\n",
    "    opt_t=0\n",
    "    max_uncert_red=0.0\n",
    "    \n",
    "    for f in range(feature_space.shape[1]):\n",
    "        b=np.linspace(min(feature_space[:,f]), max(feature_space[:,f]), 11)\n",
    "        # cut off the ends\n",
    "        b=b[1:-1]\n",
    "        #a=(max(feature_space[:,f])-min(feature_space[:,f]))/10\n",
    "        #b=[min(feature_space[:,f])+i*a for i in range(10)]\n",
    "        for t in b:\n",
    "            try:\n",
    "                filter_arr_left = np.array(feature_space[:,f]<t)\n",
    "                filter_arr_right = np.array(feature_space[:,f]>=t)\n",
    "                left_labels = np.array(labels)[filter_arr_left].tolist()\n",
    "                right_labels = np.array(labels)[filter_arr_right].tolist()\n",
    "            except TypeError:\n",
    "                print(\"Error partitioning labels\")\n",
    "          #  left_labels=[]\n",
    "          #  right_labels=[]\n",
    "          #  for i in range(len(feature_space)):\n",
    "          #      if(feature_space[i,f]<t):\n",
    "          #          left_labels.append(labels[i])\n",
    "          #      else:\n",
    "          #          right_labels.append(labels[i])\n",
    "            if(len(left_labels)==0 or len(right_labels)==0):\n",
    "                continue\n",
    "            uncertainty_red = entropy(labels)-(len(left_labels)*1.0/len(labels))*entropy(left_labels) - (len(left_labels)*1.0/len(labels))*entropy(right_labels)\n",
    "            if(uncertainty_red > max_uncert_red):\n",
    "                opt_f=f\n",
    "                opt_t=t\n",
    "    \n",
    "    return [opt_f,opt_t]\n",
    "\n",
    "def build_tree(feature_space,labels,param,live_count):\n",
    "    global tree_depth\n",
    "    if len(feature_space)<=param or live_count > 1000:\n",
    "        return Node(None,None,None,None,calculate_max_label(labels))\n",
    "    \n",
    "    live_count += 1\n",
    "    tree_depth = max(tree_depth,live_count)\n",
    "    #print(live_count)\n",
    "    \n",
    "    left_space=[]\n",
    "    left_labels=[]\n",
    "    right_space=[]\n",
    "    right_labels=[]\n",
    "    \n",
    "    [f,t]=calculate_optimal_feature_threshold(feature_space,labels)\n",
    "    #print(f,t)\n",
    "    if(f==0 and t== 0):\n",
    "        return Node(None,None,None,None,calculate_max_label(labels))\n",
    "    \n",
    "    try:\n",
    "        filter_arr_left = np.array(feature_space[:,f]<t)\n",
    "        filter_arr_right = np.array(feature_space[:,f]>=t)\n",
    "        left_space = np.array(feature_space)[filter_arr_left].tolist()\n",
    "        right_space = np.array(feature_space)[filter_arr_right].tolist()\n",
    "        left_labels = np.array(labels)[filter_arr_left].tolist()\n",
    "        right_labels = np.array(labels)[filter_arr_right].tolist()\n",
    "    except TypeError:\n",
    "        print(\"Error partitioning labels\")\n",
    "        \n",
    "    #for i in range(len(feature_space)):\n",
    "    #    if(feature_space[i][f]<t):\n",
    "    #        \n",
    "    #        left_space.append(feature_space[i])\n",
    "    #        left_labels.append(labels[i])\n",
    "    #    else:\n",
    "    #        right_space.append(feature_space[i])\n",
    "    #        right_labels.append(labels[i])\n",
    "    \n",
    "    left_node=build_tree(np.array(left_space),left_labels,param,live_count)\n",
    "    right_node=build_tree(np.array(right_space),right_labels,param,live_count)\n",
    "    \n",
    "    return Node(f,t,left_node,right_node,None)\n",
    "    \n",
    "    ## find the optimal feature and threshold\n",
    "    ## split on the optimal feature and threshold\n",
    "    ## node.left=build_tree(left_space)\n",
    "    ## node.right=build_tree(right_space)\n",
    "    ## return node\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self,num_classes,root):\n",
    "        self.num_classes=num_classes\n",
    "        self.root=root\n",
    "\n",
    "                \n",
    "\n",
    "    def train_model(self,training_data,labels,param):\n",
    "        print(\"------Pre-processing Data-----\")\n",
    "        for i in range(len(training_data)):\n",
    "            if (i == 0):\n",
    "                feature_mle_mu = training_data[i]\n",
    "                self.dim = (training_data[i].shape)[0]\n",
    "            else:\n",
    "                feature_mle_mu += training_data[i]\n",
    "            \n",
    "        feature_mle_mu = feature_mle_mu * 1.0/len(training_data)\n",
    "        \n",
    "        for i in range(len(training_data)):\n",
    "            x_minus_mu_feature = training_data[i]-feature_mle_mu\n",
    "            if (i == 0):\n",
    "                feature_mle_sigma = x_minus_mu_feature**2\n",
    "            else:\n",
    "                feature_mle_sigma += x_minus_mu_feature**2\n",
    "                \n",
    "        feature_mle_sigma = feature_mle_sigma * 1.0/len(training_data)\n",
    "        \n",
    "        keys = np.linspace(0,self.dim-1,self.dim)\n",
    "        feature_var = list(zip(keys,feature_mle_sigma))\n",
    "        \n",
    "        feature_var_sorted = sorted(feature_var, key=lambda f: f[1], reverse = True)\n",
    "        self.top200 = [int(e[0]) for e in feature_var_sorted[:200]]  \n",
    "        print(\"------Done Pre-processing Data -----\")\n",
    "        # slice the data\n",
    "        training_data = training_data[:,self.top200]\n",
    "        t0 = time.time()\n",
    "        self.root=build_tree(training_data,labels,param,0)\n",
    "        t1 = time.time()\n",
    "        print (\"Total time taken: \" + str(t1-t0))\n",
    "        \n",
    "    def predict(self,x):\n",
    "        prediction=None\n",
    "        curr_node=self.root\n",
    "        while prediction==None:\n",
    "            if curr_node.label!= None:\n",
    "                prediction=curr_node.label\n",
    "            else:\n",
    "                if(x[curr_node.feature]<curr_node.threshold):\n",
    "                    curr_node=curr_node.left\n",
    "                else:\n",
    "                    curr_node=curr_node.right\n",
    "        return prediction\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "    def testing_error(self,test_data,labels):\n",
    "        misses=0\n",
    "        test_data = test_data[:,self.top200]\n",
    "        for i in range(len(test_data)):\n",
    "            if(self.predict(test_data[i])!=labels[i]):\n",
    "                misses=misses+1\n",
    "        return (misses*1.0/len(test_data))\n",
    "            \n",
    "    \n",
    "        ##Steps:\n",
    "        ##1: return argmax P[X=x/Y=y]*P[Y=y]\n",
    "\n",
    "        #Partition = 0.7 for 70-30 split\n",
    "        \n",
    "        \n",
    "mat = spio.loadmat('hw1data.mat', squeeze_me=True)\n",
    "data_split = shuffle_and_split(mat,0.8)\n",
    "image_matrix = data_split[0]\n",
    "#move_step = build_step_for_feature(image_matrix)\n",
    "tree_depth = 0\n",
    "label_array= data_split[1]\n",
    "\n",
    "decision_tree= DecisionTree(10,None)\n",
    "#[f,t]= calculate_optimal_feature_threshold(image_matrix[:30],label_array[:30])\n",
    "decision_tree.train_model(image_matrix,label_array,10)\n",
    "\n",
    "#Training error\n",
    "print(decision_tree.testing_error(data_split[0],data_split[1]))\n",
    "#Test Error\n",
    "print(decision_tree.testing_error(data_split[2],data_split[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4707142857142857\n",
      "0.5586666666666666\n"
     ]
    }
   ],
   "source": [
    "#Training error\n",
    "print(decision_tree.testing_error(data_split[0],data_split[1]))\n",
    "#Test Error\n",
    "print(decision_tree.testing_error(data_split[2],data_split[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.095\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_model() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2f2fac8edd1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: train_model() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
