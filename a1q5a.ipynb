{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "{'Test Error': 0.23333333333333334, 'Training Size': 3000, 'Testing Size': 300, 'Predicted': [5, 8, 9, 0, 0, 9, 0, 8, 8, 3, 8, 0, 6, 9, 2, 8, 7, 9, 4, 3, 1, 5, 8, 8, 1, 9, 9, 5, 3, 8, 8, 2, 5, 3, 4, 5, 4, 0, 8, 0, 3, 6, 2, 8, 8, 3, 8, 8, 9, 3, 8, 9, 9, 8, 7, 1, 2, 9, 3, 0, 2, 0, 8, 9, 4, 7, 3, 1, 4, 3, 3, 1, 3, 1, 2, 8, 6, 8, 3, 8, 5, 1, 3, 3, 6, 8, 3, 2, 3, 3, 7, 3, 3, 3, 8, 3, 8, 2, 8, 9, 1, 7, 9, 3, 0, 1, 3, 6, 5, 6, 3, 3, 3, 7, 1, 7, 9, 8, 9, 1, 8, 4, 8, 8, 4, 1, 6, 3, 8, 7, 9, 5, 3, 4, 2, 0, 6, 0, 4, 8, 3, 8, 2, 7, 8, 9, 8, 6, 5, 8, 8, 0, 0, 9, 8, 0, 1, 1, 6, 9, 5, 3, 2, 3, 8, 8, 2, 8, 7, 9, 7, 3, 0, 4, 3, 0, 4, 7, 8, 9, 3, 1, 8, 4, 3, 4, 3, 5, 9, 3, 0, 2, 3, 9, 8, 2, 4, 3, 2, 3, 3, 0, 8, 3, 7, 0, 3, 4, 3, 8, 8, 7, 0, 8, 6, 8, 2, 7, 8, 3, 0, 9, 3, 4, 7, 9, 5, 8, 3, 3, 9, 3, 3, 8, 9, 2, 2, 1, 5, 3, 7, 5, 4, 8, 8, 3, 7, 8, 1, 1, 6, 3, 9, 7, 9, 1, 9, 4, 8, 9, 2, 9, 3, 6, 2, 8, 1, 0, 7, 2, 4, 9, 3, 7, 3, 0, 5, 5, 6, 4, 1, 2, 2, 8, 4, 0, 3, 7, 7, 1, 8, 3, 8, 1, 9, 8, 3, 0, 3, 9], 'Actual': [5, 8, 9, 0, 0, 4, 0, 1, 9, 3, 3, 0, 6, 9, 2, 3, 7, 9, 4, 3, 1, 5, 8, 8, 1, 4, 9, 6, 3, 8, 8, 2, 5, 6, 4, 5, 4, 0, 8, 0, 8, 6, 3, 8, 2, 3, 8, 6, 9, 4, 9, 9, 9, 8, 7, 1, 1, 4, 3, 0, 2, 0, 1, 9, 4, 7, 3, 1, 4, 7, 3, 1, 3, 1, 2, 6, 6, 0, 3, 8, 5, 1, 9, 9, 6, 9, 3, 2, 3, 3, 7, 6, 2, 5, 5, 5, 6, 2, 7, 9, 1, 7, 9, 3, 0, 1, 3, 6, 5, 6, 6, 5, 3, 7, 1, 7, 9, 8, 9, 1, 5, 4, 8, 1, 4, 1, 6, 0, 8, 7, 9, 5, 3, 4, 2, 0, 6, 0, 4, 4, 3, 2, 3, 7, 1, 7, 6, 6, 5, 8, 8, 0, 0, 9, 1, 0, 1, 1, 6, 9, 5, 3, 2, 3, 7, 8, 2, 8, 7, 9, 7, 3, 0, 9, 3, 0, 4, 7, 8, 9, 5, 1, 8, 4, 3, 4, 3, 5, 9, 3, 0, 2, 5, 9, 8, 2, 4, 3, 2, 4, 2, 0, 1, 3, 7, 0, 3, 4, 8, 8, 8, 7, 0, 8, 6, 8, 2, 7, 8, 5, 0, 9, 3, 4, 4, 9, 5, 4, 5, 9, 9, 4, 3, 8, 9, 2, 9, 1, 5, 9, 7, 5, 4, 8, 8, 3, 7, 8, 1, 1, 6, 6, 9, 7, 9, 1, 9, 4, 8, 9, 2, 7, 2, 6, 7, 8, 1, 0, 7, 2, 4, 9, 6, 7, 3, 0, 5, 5, 6, 4, 1, 2, 3, 8, 4, 0, 9, 7, 7, 1, 8, 6, 2, 1, 9, 4, 5, 0, 5, 9]}\n",
      "Training time: 2.200637102127075\n",
      "Testing time: 4.446920871734619\n",
      "Total time taken: 6.647557973861694\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import time\n",
    "\n",
    "class GaussianProbabilisticModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_classes = 0\n",
    "        self.classes = []\n",
    "        self.mle_mu_map = {}\n",
    "        self.mle_sigma_map = {}\n",
    "        self.class_prob_map = {}\n",
    "        self.dim = 0\n",
    "        self.topN_features = 200\n",
    "        self.l = 0.1\n",
    "\n",
    "    def __log_gaussian_pdf(self,x,mu,sigma,sigma_new_I_given = None,logdet_given = None,compute_inv_and_det = True):\n",
    "        # calculate log of f(x)~multivariate Normal density\n",
    "        # sigma is adjusted by 0.1*I to avoid inverting a singular matrix\n",
    "        dim_of_cut_data = len(mu)\n",
    "        sigma_new = np.matrix(sigma+self.l*np.eye(dim_of_cut_data))\n",
    "        \n",
    "        # can feed the inverse and det in directly so that we don't have to compute it every time\n",
    "        if (compute_inv_and_det):\n",
    "            sigma_new_I = sigma_new.I\n",
    "            (sign, logdet) = np.linalg.slogdet(sigma_new)\n",
    "        else:\n",
    "            sigma_new_I = sigma_new_I_given\n",
    "            logdet = logdet_given\n",
    "        \n",
    "        C = -0.5*logdet + (-dim_of_cut_data*0.5)*np.log(2*math.pi)\n",
    "        x_minus_mu_mat = np.matrix(x-mu).T\n",
    "        result = float(-0.5*x_minus_mu_mat.T*sigma_new_I*x_minus_mu_mat)\n",
    "\n",
    "        return result\n",
    "                \n",
    "       \n",
    "    def train_model(self,training_data,labels):\n",
    "        # Steps:\n",
    "        # 1: Find the N=200 most significant features, and slice the data based on those features\n",
    "        # 2: Partition data according to labels\n",
    "        # 3: Compute MLE of mu and sigma for each label\n",
    "        \n",
    "        # Step 1.1 - find the MLE of mu and sigma for each feature over the entire dataset\n",
    "        for i in range(len(training_data)):\n",
    "            if (i == 0):\n",
    "                feature_mle_mu = training_data[i]\n",
    "                self.dim = (training_data[i].shape)[0]\n",
    "            else:\n",
    "                feature_mle_mu += training_data[i]\n",
    "            \n",
    "        feature_mle_mu = feature_mle_mu * 1.0/len(training_data)\n",
    "        \n",
    "        for i in range(len(training_data)):\n",
    "            x_minus_mu_feature = training_data[i]-feature_mle_mu\n",
    "            if (i == 0):\n",
    "                feature_mle_sigma = x_minus_mu_feature**2\n",
    "            else:\n",
    "                feature_mle_sigma += x_minus_mu_feature**2\n",
    "                \n",
    "        feature_mle_sigma = feature_mle_sigma * 1.0/len(training_data)\n",
    "        \n",
    "        # Step 1.2 - find the N=200 most significant features (features exhibiting the largest variance)\n",
    "        keys = np.linspace(0,self.dim-1,self.dim)\n",
    "        feature_var = list(zip(keys,feature_mle_sigma))\n",
    "        \n",
    "        feature_var_sorted = sorted(feature_var, key=lambda f: f[1], reverse = True)\n",
    "        self.topN = [int(e[0]) for e in feature_var_sorted[:self.topN_features]]  \n",
    "        \n",
    "        # Step 1.3 - slice the training data on the most significant features\n",
    "        training_data = training_data[:,self.topN]\n",
    "        self.train_size = len(training_data)\n",
    "        nums={}\n",
    "        \n",
    "        # Step 2.1 - calculate MLE of mu for each label\n",
    "        for i in range(len(training_data)):\n",
    "            if not (labels[i] in self.mle_mu_map):\n",
    "                self.mle_mu_map[labels[i]] = training_data[i]\n",
    "                self.classes += [labels[i]]\n",
    "                nums[labels[i]] = 1\n",
    "                self.num_classes += 1\n",
    "                \n",
    "            else:\n",
    "                self.mle_mu_map[labels[i]] += training_data[i]\n",
    "                nums[labels[i]] += 1\n",
    "                \n",
    "        for i in self.classes:\n",
    "            self.mle_mu_map[i]=(1.0/nums[i])*self.mle_mu_map[i]\n",
    "        \n",
    "        # Step 2.2 - calculate MLE of sigma for each label\n",
    "        for i in range(len(training_data)):\n",
    "            # this is a column vector\n",
    "            x_minus_mu = np.matrix(training_data[i]-self.mle_mu_map[labels[i]]).T\n",
    "            \n",
    "            if not (labels[i] in self.mle_sigma_map):\n",
    "                self.mle_sigma_map[labels[i]]=(x_minus_mu)*(x_minus_mu.T)\n",
    "            else:\n",
    "                self.mle_sigma_map[labels[i]]+=(x_minus_mu)*(x_minus_mu.T)\n",
    "               \n",
    "        for i in self.classes:\n",
    "            self.mle_sigma_map[i]=(1.0/nums[i])*self.mle_sigma_map[i]\n",
    "            self.class_prob_map[i]=(nums[i]*1.0)/len(training_data)\n",
    "         \n",
    "        # precalculate matrix inverses and determinants to use in prediction function\n",
    "        # the \"new\" refers to computing the inverse of sigma + l*I \n",
    "        self.sigma_new_inverses = {}\n",
    "        self.logdets = {}\n",
    "        for i in self.classes:\n",
    "            self.sigma_new_inverses[i]=np.matrix(self.mle_sigma_map[i] + self.l*np.eye(self.topN_features)).I\n",
    "            self.logdets[i]=np.linalg.slogdet(np.matrix(self.mle_sigma_map[i] + self.l*np.eye(self.topN_features)))[1]\n",
    "            \n",
    "    def predict(self,x):\n",
    "        # prediction is equal to the maximum likelihood class\n",
    "        prediction=-1\n",
    "        curr_max=-1e300;\n",
    "        \n",
    "        for i in self.classes:\n",
    "            p = self.__log_gaussian_pdf(x,self.mle_mu_map[i],self.mle_sigma_map[i],\n",
    "                                       sigma_new_I_given = self.sigma_new_inverses[i],\n",
    "                                       logdet_given = self.logdets[i],\n",
    "                                       compute_inv_and_det = False) + np.log(self.class_prob_map[i])\n",
    "            if(p>curr_max):\n",
    "                curr_max=p\n",
    "                prediction=i\n",
    "        return prediction\n",
    "                        \n",
    "    def test_model(self,test_data,labels):\n",
    "        misses=0        \n",
    "        # slice the data based on the most significant features\n",
    "        test_data = test_data[:,self.topN]\n",
    "        self.test_size = len(test_data)\n",
    "        results = {'Test Error': [], 'Training Size': [], 'Testing Size': [], 'Predicted': [], 'Actual': []}\n",
    "        results['Training Size'] = self.train_size\n",
    "        results['Testing Size'] = self.test_size\n",
    "\n",
    "        for i in range(len(test_data)):\n",
    "            pred = self.predict(test_data[i])\n",
    "            actual = labels[i]\n",
    "            \n",
    "            results['Predicted'] += [pred]\n",
    "            results['Actual'] += [actual]\n",
    "            \n",
    "            if(pred != actual):\n",
    "                misses=misses+1\n",
    "                \n",
    "        results['Test Error'] = misses*1.0/len(test_data)\n",
    "        return results\n",
    "\n",
    "\n",
    "mat = spio.loadmat('hw1data.mat', squeeze_me=True)\n",
    "image_matrix=mat['X']\n",
    "label_array=mat['Y']   \n",
    "\n",
    "tstart = time.time()\n",
    "    \n",
    "gaussian_model= GaussianProbabilisticModel()\n",
    "gaussian_model.train_model(image_matrix[:3000,:],label_array[:3000])\n",
    "tmid = time.time()\n",
    "print('Training complete')\n",
    "print(gaussian_model.test_model(image_matrix[3001:3301,:],label_array[3001:3301]))\n",
    "\n",
    "tend = time.time()\n",
    "print(\"Training time: \" + str(tmid-tstart))\n",
    "print(\"Testing time: \" + str(tend-tmid))\n",
    "print(\"Total time taken: \" + str(tend-tstart))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
