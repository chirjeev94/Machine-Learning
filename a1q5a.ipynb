{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "{'Test Error': 0.21, 'Training Size': 1000, 'Testing Size': 100, 'Predicted': [2, 0, 9, 8, 7, 6, 4, 7, 0, 1, 4, 8, 2, 6, 1, 9, 9, 3, 8, 9, 6, 3, 7, 7, 1, 1, 8, 3, 9, 1, 1, 4, 6, 8, 3, 3, 0, 3, 3, 0, 3, 0, 8, 7, 1, 7, 5, 1, 3, 2, 2, 3, 3, 9, 5, 2, 1, 9, 8, 7, 2, 5, 4, 0, 3, 3, 9, 7, 6, 0, 1, 9, 3, 3, 3, 7, 1, 4, 1, 8, 7, 5, 2, 7, 5, 1, 8, 3, 5, 0, 8, 9, 6, 3, 4, 0, 9, 1, 0, 7], 'Actual': [2, 2, 9, 5, 7, 6, 4, 9, 0, 1, 4, 8, 2, 6, 1, 9, 7, 3, 8, 9, 6, 3, 7, 7, 1, 1, 7, 3, 9, 1, 1, 4, 6, 8, 2, 8, 0, 3, 3, 0, 5, 0, 2, 7, 1, 7, 5, 1, 2, 2, 2, 2, 3, 9, 5, 2, 1, 9, 8, 7, 2, 5, 4, 0, 2, 2, 4, 7, 6, 0, 1, 9, 2, 2, 5, 7, 1, 4, 1, 2, 7, 5, 2, 7, 5, 1, 8, 2, 5, 0, 8, 5, 6, 3, 3, 0, 9, 1, 0, 7]}\n",
      "Total time taken: 12.373589515686035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import time\n",
    "\n",
    "class GaussianProbabilisticModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_classes = 0\n",
    "        self.classes = []\n",
    "        self.mle_mu_map = {}\n",
    "        self.mle_sigma_map = {}\n",
    "        self.class_prob_map = {}\n",
    "        self.dim = 0\n",
    "        self.topN_features = 200\n",
    "\n",
    "    def __log_gaussian_pdf(self,x,mu,sigma):\n",
    "        # calculate log of f(x)~multivariate Normal density\n",
    "        # sigma is adjusted by 0.1*I to avoid inverting a singular matrix\n",
    "        \n",
    "        ndim = len(mu)\n",
    "        sigma_new = np.matrix(sigma+0.1*np.eye(ndim))\n",
    "        \n",
    "        det = np.linalg.det(sigma_new)\n",
    "        C = (det)**(-0.5)*(2*math.pi)**(-ndim*0.5)\n",
    "        x_minus_mu_mat = np.matrix(x-mu).T\n",
    "        result = np.log(C) + float(-0.5*x_minus_mu_mat.T*sigma_new.I*x_minus_mu_mat)\n",
    "\n",
    "        return result\n",
    "                \n",
    "       \n",
    "    def train_model(self,training_data,labels):\n",
    "        # Steps:\n",
    "        # 1: Find the N=200 most significant features, and slice the data based on those features\n",
    "        # 2: Partition data according to labels\n",
    "        # 3: Compute MLE of mu and sigma for each label\n",
    "        \n",
    "        # Step 1.1 - find the MLE of mu and sigma for each feature over the entire dataset\n",
    "        for i in range(len(training_data)):\n",
    "            if (i == 0):\n",
    "                feature_mle_mu = training_data[i]\n",
    "                self.dim = (training_data[i].shape)[0]\n",
    "            else:\n",
    "                feature_mle_mu += training_data[i]\n",
    "            \n",
    "        feature_mle_mu = feature_mle_mu * 1.0/len(training_data)\n",
    "        \n",
    "        for i in range(len(training_data)):\n",
    "            x_minus_mu_feature = training_data[i]-feature_mle_mu\n",
    "            if (i == 0):\n",
    "                feature_mle_sigma = x_minus_mu_feature**2\n",
    "            else:\n",
    "                feature_mle_sigma += x_minus_mu_feature**2\n",
    "                \n",
    "        feature_mle_sigma = feature_mle_sigma * 1.0/len(training_data)\n",
    "        \n",
    "        # Step 1.2 - find the N=200 most significant features (features exhibiting the largest variance)\n",
    "        keys = np.linspace(0,self.dim-1,self.dim)\n",
    "        feature_var = list(zip(keys,feature_mle_sigma))\n",
    "        \n",
    "        feature_var_sorted = sorted(feature_var, key=lambda f: f[1], reverse = True)\n",
    "        self.topN = [int(e[0]) for e in feature_var_sorted[:self.topN_features]]  \n",
    "        \n",
    "        # Step 1.3 - slice the training data on the most significant features\n",
    "        training_data = training_data[:,self.topN]\n",
    "        self.train_size = len(training_data)\n",
    "        nums={}\n",
    "        \n",
    "        # Step 2.1 - calculate MLE of mu for each label\n",
    "        for i in range(len(training_data)):\n",
    "            if not (labels[i] in self.mle_mu_map):\n",
    "                self.mle_mu_map[labels[i]] = training_data[i]\n",
    "                self.classes += [labels[i]]\n",
    "                nums[labels[i]] = 1\n",
    "                self.num_classes += 1\n",
    "                \n",
    "            else:\n",
    "                self.mle_mu_map[labels[i]] += training_data[i]\n",
    "                nums[labels[i]] += 1\n",
    "                \n",
    "        for i in self.classes:\n",
    "            self.mle_mu_map[i]=(1.0/nums[i])*self.mle_mu_map[i]\n",
    "        \n",
    "        # Step 2.2 - calculate MLE of sigma for each label\n",
    "        for i in range(len(training_data)):\n",
    "            # this is a column vector\n",
    "            x_minus_mu = np.matrix(training_data[i]-self.mle_mu_map[labels[i]]).T\n",
    "            \n",
    "            if not (labels[i] in self.mle_sigma_map):\n",
    "                self.mle_sigma_map[labels[i]]=(x_minus_mu)*(x_minus_mu.T)\n",
    "            else:\n",
    "                self.mle_sigma_map[labels[i]]+=(x_minus_mu)*(x_minus_mu.T)\n",
    "               \n",
    "        for i in self.classes:\n",
    "            self.mle_sigma_map[i]=(1.0/nums[i])*self.mle_sigma_map[i]\n",
    "            self.class_prob_map[i]=(nums[i]*1.0)/len(training_data)\n",
    "            \n",
    "    def predict(self,x):\n",
    "        # prediction is equal to the maximum likelihood class\n",
    "        prediction=0\n",
    "        curr_max=-1e300;\n",
    "        for i in range(self.num_classes):\n",
    "            p = self.__log_gaussian_pdf(x,self.mle_mu_map[i],self.mle_sigma_map[i]) + np.log(self.class_prob_map[i])\n",
    "            if(p>curr_max):\n",
    "                curr_max=p\n",
    "                prediction=i\n",
    "        return prediction\n",
    "                        \n",
    "    def test_model(self,test_data,labels):\n",
    "        misses=0        \n",
    "        # slice the data based on the most significant features\n",
    "        test_data = test_data[:,self.topN]\n",
    "        self.test_size = len(test_data)\n",
    "        results = {'Test Error': [], 'Training Size': [], 'Testing Size': [], 'Predicted': [], 'Actual': []}\n",
    "        results['Training Size'] = self.train_size\n",
    "        results['Testing Size'] = self.test_size\n",
    "\n",
    "        for i in range(len(test_data)):\n",
    "            pred = self.predict(test_data[i])\n",
    "            actual = labels[i]\n",
    "            \n",
    "            results['Predicted'] += [pred]\n",
    "            results['Actual'] += [actual]\n",
    "            \n",
    "            if(pred != actual):\n",
    "                misses=misses+1\n",
    "                \n",
    "        results['Test Error'] = misses*1.0/len(test_data)\n",
    "        return results\n",
    "\n",
    "\n",
    "mat = spio.loadmat('hw1data.mat', squeeze_me=True)\n",
    "image_matrix=mat['X']\n",
    "label_array=mat['Y']   \n",
    "\n",
    "tstart = time.time()\n",
    "    \n",
    "gaussian_model= GaussianProbabilisticModel()\n",
    "gaussian_model.train_model(image_matrix[:1000,:],label_array[:1000])\n",
    "print('Training complete')\n",
    "print(gaussian_model.test_model(image_matrix[1001:1101,:],label_array[1001:1101]))\n",
    "\n",
    "tend = time.time()\n",
    "print(\"Total time taken: \" + str(tend-tstart))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.2  0.5  0.2  1.5  0.4  0.5  0.4  3.9]\n",
      "-inf\n",
      "-5014806.3369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "def gaussian1(x,mu,sigma):\n",
    "    # calculate f(x)~multivariate Normal density\n",
    "    rv=stats.multivariate_normal(mean=mu,cov=sigma)\n",
    "    return rv.pdf(x)\n",
    "def gaussian2(x,mu,sigma):\n",
    "    det = np.linalg.det(sigma)\n",
    "    C = (det)**(-0.5)*(2*math.pi)**(-len(mu.tolist())*0.5)\n",
    "    x_minus_mu_mat = np.matrix(x-mu).T\n",
    "    sigma_mat = np.matrix(sigma)\n",
    "    return np.log(C) + float(-0.5*x_minus_mu_mat.T*sigma_mat.I*x_minus_mu_mat)\n",
    "    \n",
    "x = np.array([1,2,6000])\n",
    "mu = np.array([0.6,0.7,0.4])\n",
    "sigma = np.array([[1,0.2,0.5],\n",
    "                  [0.2,1.5,0.4],\n",
    "                  [0.5,0.4,3.9]])\n",
    "\n",
    "print(sigma.flatten())\n",
    "print(np.log(gaussian1(x,mu,sigma)))\n",
    "print(gaussian2(x,mu,sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
